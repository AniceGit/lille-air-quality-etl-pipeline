End-to-end data pipeline for monitoring air quality in Lille using Python, Parquet, DuckDB, and Streamlit.
# Lille Air Quality ETL Pipeline

This project demonstrates an end-to-end data engineering workflow to collect, process, store, and visualize air quality data for the city of Lille, France.

It covers all key components of a modern data pipeline:

- **Data Ingestion**: Fetching real-time or historical data from open APIs.
- **Data Transformation**: Cleaning and formatting the data using Pandas.
- **Data Storage**: Saving the processed data efficiently in Parquet format.
- **SQL Query Layer**: Exploring data with DuckDB for fast local analytics.
- **Visualization**: Building an interactive dashboard with Streamlit and Plotly/Folium.

ğŸ§  **Goal**: Showcase practical data engineering skills (ETL, file formats, automation, dashboards) using only Python and open tools.

ğŸ”§ Technologies: `Python`, `Pandas`, `Parquet`, `DuckDB`, `Streamlit`, `Requests`, `Plotly`, `Folium`.

ğŸ“ Location: Lille, France ğŸ‡«ğŸ‡·

